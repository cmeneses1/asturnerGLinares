{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "advised-restriction",
   "metadata": {},
   "source": [
    "# Creación y cálculo de las etiquetas: B_Añadir_Etiquetas.ipynb\n",
    "En este *notebook* cargamos el binario que contiene nuestro censo procesado por spacy-stanza. A continuación seguiremos un proceso denso, pero repetivo para determinar el año, parroquia y localidad asignada a cada persona del censo. Para cada característica se sigue el mismo método interactivo:\n",
    "- Encontrar expresiones en el texto que puedan indicar la característica buscada. Por ejemplo, si encontramos la frase \"parroquia de\".\n",
    "- A continuación recorremos una a una todas las coincidencias. Muchas veces, el usuario no tendrá que verificar una a una todas las coincidencias, porque se ha programado ya muchos casos para que la respuesta sea automática. En otros deberá intervenir, por ejemplo para determinar si un Carcedo es el Carcedo de Lago o el Carcedo de Lomes.\n",
    "- Por último, asignamos a todas las personas indicadas dicha característica en una extensión de *Span* (ver documentación de SpaCy). Las caracterísiticas asignadas están programadas para encontrar información que se ha recogido en el *notebook* Z_Ayudas, por ejemplo, la geolocalización."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "forty-velvet",
   "metadata": {},
   "source": [
    "## Inicio\n",
    "### Importamos las librerías a usar\n",
    "Lo haremos siempre al comienzo de cada *notebook*."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "necessary-uniform",
   "metadata": {},
   "outputs": [],
   "source": [
    "import spacy\n",
    "import spacy_stanza\n",
    "from spacy import displacy\n",
    "from spacy.tokens import  Span, DocBin\n",
    "from spacy.matcher import Matcher, PhraseMatcher\n",
    "\n",
    "# Ejecutamos nuestras funciones y ayudas creadas para la ocasión. Están en el notebook Z_Funciones.ipynb y Z_Ayudas.ipynb.\n",
    "%run './Z_Funciones.ipynb'\n",
    "%run './Z_Ayudas.ipynb'"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "binary-excess",
   "metadata": {},
   "source": [
    "### Especificamos la direcciones y configuraciones a usar\n",
    "Esta sección es la que podemos personalizar o modificar a conveniencia según el archivo que queramos procesar, dónde lo queremos guardar, etc. Contiene los siguientes datos:\n",
    "- `direccionbin`: es la dirección donde vamos a guardar el archivo procesado por spacy-stanza. Es un archivo binario.\n",
    "- `nlpconfig`: es la variable que determina las características del pipeline de procesamiento de spacy-stanza. Por ejemplo, contiene el idioma, cuántas frases procesamos de una sola vez, etc.\n",
    "- `direcciontxt`: es la dirección donde tenemos guardado el txt de estudio.\n",
    "- `direcciónpueblos`: es la dirección donde donde se guarda el archivo csv con la información de las entradas y su geolocalización."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "capital-residence",
   "metadata": {},
   "outputs": [],
   "source": [
    "direccionbin = './Documentos/Padronbin'\n",
    "direccionbin_tags = './Documentos/Padronbin_tags'\n",
    "direcciontxt = './Documentos/PadronOCRPrueba.txt'\n",
    "direcciónpueblos = './Documentos/GeolocLocalidadesPrueba.tsv'\n",
    "# direccionbin = './Privado/PadronbinTOTAL'\n",
    "# direccionbin_tags = './Privado/Padronbin_tagsTOTAL'\n",
    "# direcciontxt = './Privado/PadronOCR.txt'\n",
    "# direcciónpueblos = './Privado/GeolocLocalidadesTOTAL.tsv'\n",
    "nlpconfig = {\n",
    "    'name': 'es', # Language code for the language to build the Pipeline in\n",
    "    'tokenize_batch_size': 32, # Enseguida vamos a cambiarlo por la cantidad máxima de palabras que alberga una frase en nuestro documento.\n",
    "    'ner_batch_size': 32 # Enseguida vamos a cambiarlo por la cantidad máxima de palabras que alberga una frase en nuestro documento.\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "cloudy-employee",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "El número de palabras máximas es 33. \n",
      "Añadiendo un 25%, tomaremos el número 41.\n"
     ]
    }
   ],
   "source": [
    "# Contamos las palabras y corregimos el diccionario nlpconfig\n",
    "numero1 = cuenta_palabras_max(direcciontxt)\n",
    "numero2 = int(numero1 * 1.25)\n",
    "\n",
    "nlpconfig['ner_batch_size'] = numero2\n",
    "nlpconfig['tokenize_batch_size'] = numero2\n",
    "\n",
    "print(\"El número de palabras máximas es\", str(numero1) + \".\", \"\\nAñadiendo un 25%, tomaremos el número\", str(numero2) + \".\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "foreign-graphics",
   "metadata": {},
   "source": [
    "### Cargamos el pipeline de procesamiento\n",
    "\n",
    "Creamos los pipelines (las funciones que procesan nuestro archivo de análisis). `nlp1` es el pipeline de spacy-stanza y `nlp2` es el de spacy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "acting-passion",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2021-08-27 09:21:28 INFO: Loading these models for language: es (Spanish):\n",
      "=======================\n",
      "| Processor | Package |\n",
      "-----------------------\n",
      "| tokenize  | ancora  |\n",
      "| mwt       | ancora  |\n",
      "| pos       | ancora  |\n",
      "| lemma     | ancora  |\n",
      "| depparse  | ancora  |\n",
      "| ner       | conll02 |\n",
      "=======================\n",
      "\n",
      "/home/carlos-eduardo/anaconda3/envs/PMLatest/lib/python3.8/site-packages/torch/cuda/__init__.py:52: UserWarning: CUDA initialization: Found no NVIDIA driver on your system. Please check that you have an NVIDIA GPU and installed a driver from http://www.nvidia.com/Download/index.aspx (Triggered internally at  /pytorch/c10/cuda/CUDAFunctions.cpp:100.)\n",
      "  return torch._C._cuda_getDeviceCount() > 0\n",
      "2021-08-27 09:21:28 INFO: Use device: cpu\n",
      "2021-08-27 09:21:28 INFO: Loading: tokenize\n",
      "2021-08-27 09:21:28 INFO: Loading: mwt\n",
      "2021-08-27 09:21:28 INFO: Loading: pos\n",
      "2021-08-27 09:21:32 INFO: Loading: lemma\n",
      "2021-08-27 09:21:32 INFO: Loading: depparse\n",
      "2021-08-27 09:21:35 INFO: Loading: ner\n",
      "2021-08-27 09:21:44 INFO: Done loading processors!\n"
     ]
    }
   ],
   "source": [
    "nlp = spacy_stanza.load_pipeline(**nlpconfig)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "smart-noise",
   "metadata": {},
   "source": [
    "### Revertimos la serializamos\n",
    "La palabra serializar se refiere a guardar nuestro documento procesado `doc` a un archivo binario que se pueda alojar en un disco duro. Así no tenemos que procesar el documento de texto cada vez que abrimos *Jupyter Lab*. Cargamos el binario en la dirección `direccionbin`. Para ello usaremos la función `revertir_serializacion` definida en el archivo *funciones_Spacy.ipynb*."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "velvet-yield",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Nota: esta función requiere los siguientes módulo o funciones:\n",
      " import spacy\n",
      " from spacy.tokens import Doc\n",
      " from spacy.tokens import DocBin\n",
      " Si no los usa se producirá un error.\n"
     ]
    }
   ],
   "source": [
    "doc = revertir_serializacion(direccionbin, nlp)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "western-chicken",
   "metadata": {},
   "source": [
    "### Mirando las entidades nombradas que hemos resuelto\n",
    "Vamos a generar un documento de texto que muestre cada frase señalando las EN resueltas. Para la lengua española, spacy-stanza resuelve tres tipos de entidad nombrada, a saber, personas (PER), lugar (LOC), organización (ORG) y miscelanea (MISC).\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "allied-swaziland",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<span class=\"tex2jax_ignore\"><div class=\"entities\" style=\"line-height: 2.5; direction: ltr\">\n",
       "<mark class=\"entity\" style=\"background: #7DFF6E; padding: 0.45em 0.6em; margin: 0 0.25em; line-height: 1; border-radius: 0.35em;\">\n",
       "    PARROQUIA DE ERIAS\n",
       "    <span style=\"font-size: 0.8em; font-weight: bold; line-height: 1; border-radius: 0.35em; vertical-align: middle; margin-left: 0.5rem\">MISC</span>\n",
       "</mark>\n",
       " \n",
       "<mark class=\"entity\" style=\"background: #7DFF6E; padding: 0.45em 0.6em; margin: 0 0.25em; line-height: 1; border-radius: 0.35em;\">\n",
       "    Tomo 2\n",
       "    <span style=\"font-size: 0.8em; font-weight: bold; line-height: 1; border-radius: 0.35em; vertical-align: middle; margin-left: 0.5rem\">MISC</span>\n",
       "</mark>\n",
       ". Año 1698. Folios 10 v.* al 12. Empadronadores locales: Por el estado de hijosdalgo: \n",
       "<mark class=\"entity\" style=\"background: #6EC5FF; padding: 0.45em 0.6em; margin: 0 0.25em; line-height: 1; border-radius: 0.35em;\">\n",
       "    Francisco López de Herías\n",
       "    <span style=\"font-size: 0.8em; font-weight: bold; line-height: 1; border-radius: 0.35em; vertical-align: middle; margin-left: 0.5rem\">PER</span>\n",
       "</mark>\n",
       ", vecino del lugar de \n",
       "<mark class=\"entity\" style=\"background: #F16EFF; padding: 0.45em 0.6em; margin: 0 0.25em; line-height: 1; border-radius: 0.35em;\">\n",
       "    Herías\n",
       "    <span style=\"font-size: 0.8em; font-weight: bold; line-height: 1; border-radius: 0.35em; vertical-align: middle; margin-left: 0.5rem\">LOC</span>\n",
       "</mark>\n",
       ". Por el estado general de labradores: \n",
       "<mark class=\"entity\" style=\"background: #6EC5FF; padding: 0.45em 0.6em; margin: 0 0.25em; line-height: 1; border-radius: 0.35em;\">\n",
       "    Pedro Díaz\n",
       "    <span style=\"font-size: 0.8em; font-weight: bold; line-height: 1; border-radius: 0.35em; vertical-align: middle; margin-left: 0.5rem\">PER</span>\n",
       "</mark>\n",
       ", vecino del lugar de \n",
       "<mark class=\"entity\" style=\"background: #F16EFF; padding: 0.45em 0.6em; margin: 0 0.25em; line-height: 1; border-radius: 0.35em;\">\n",
       "    Sarzol\n",
       "    <span style=\"font-size: 0.8em; font-weight: bold; line-height: 1; border-radius: 0.35em; vertical-align: middle; margin-left: 0.5rem\">LOC</span>\n",
       "</mark>\n",
       ". \n",
       "<mark class=\"entity\" style=\"background: #7DFF6E; padding: 0.45em 0.6em; margin: 0 0.25em; line-height: 1; border-radius: 0.35em;\">\n",
       "    ERIAS\n",
       "    <span style=\"font-size: 0.8em; font-weight: bold; line-height: 1; border-radius: 0.35em; vertical-align: middle; margin-left: 0.5rem\">MISC</span>\n",
       "</mark>\n",
       " 253. «Primeramente el \n",
       "<mark class=\"entity\" style=\"background: #6EC5FF; padding: 0.45em 0.6em; margin: 0 0.25em; line-height: 1; border-radius: 0.35em;\">\n",
       "    Licenciado Alonsso Lopez de Erias\n",
       "    <span style=\"font-size: 0.8em; font-weight: bold; line-height: 1; border-radius: 0.35em; vertical-align: middle; margin-left: 0.5rem\">PER</span>\n",
       "</mark>\n",
       ", clérigo \n",
       "<mark class=\"entity\" style=\"background: #6EC5FF; padding: 0.45em 0.6em; margin: 0 0.25em; line-height: 1; border-radius: 0.35em;\">\n",
       "    Presbítero\n",
       "    <span style=\"font-size: 0.8em; font-weight: bold; line-height: 1; border-radius: 0.35em; vertical-align: middle; margin-left: 0.5rem\">PER</span>\n",
       "</mark>\n",
       ", ijodalgo notorio.» 254. «\n",
       "<mark class=\"entity\" style=\"background: #6EC5FF; padding: 0.45em 0.6em; margin: 0 0.25em; line-height: 1; border-radius: 0.35em;\">\n",
       "    Francisco Lopez de Erias\n",
       "    <span style=\"font-size: 0.8em; font-weight: bold; line-height: 1; border-radius: 0.35em; vertical-align: middle; margin-left: 0.5rem\">PER</span>\n",
       "</mark>\n",
       ", empadronador deste \n",
       "<mark class=\"entity\" style=\"background: #6EC5FF; padding: 0.45em 0.6em; margin: 0 0.25em; line-height: 1; border-radius: 0.35em;\">\n",
       "    Padron\n",
       "    <span style=\"font-size: 0.8em; font-weight: bold; line-height: 1; border-radius: 0.35em; vertical-align: middle; margin-left: 0.5rem\">PER</span>\n",
       "</mark>\n",
       " por los ijosdalgo, lo puso el dicho \n",
       "<mark class=\"entity\" style=\"background: #6EC5FF; padding: 0.45em 0.6em; margin: 0 0.25em; line-height: 1; border-radius: 0.35em;\">\n",
       "    Pedro Diaz\n",
       "    <span style=\"font-size: 0.8em; font-weight: bold; line-height: 1; border-radius: 0.35em; vertical-align: middle; margin-left: 0.5rem\">PER</span>\n",
       "</mark>\n",
       ", empadronador por el estado pechero, por ijodalgo notorio y \n",
       "<mark class=\"entity\" style=\"background: #6EC5FF; padding: 0.45em 0.6em; margin: 0 0.25em; line-height: 1; border-radius: 0.35em;\">\n",
       "    Juan de Herias\n",
       "    <span style=\"font-size: 0.8em; font-weight: bold; line-height: 1; border-radius: 0.35em; vertical-align: middle; margin-left: 0.5rem\">PER</span>\n",
       "</mark>\n",
       " su ijo lo mismo.</div></span>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "inicio = 0\n",
    "final = 110\n",
    "colors = {\"PER\": \"#6EC5FF\",\n",
    "         \"LOC\": \"#F16EFF\",\n",
    "         \"ORG\": \"#FFA86E\",\n",
    "         \"MISC\": \"#7DFF6E\"}\n",
    "options = {\"ents\": [\"PER\", \"LOC\", \"ORG\", \"MISC\"], \"colors\": colors}\n",
    "\n",
    "displacy.render(doc[inicio:final].as_doc(), style=\"ent\", jupyter=True, options=options)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "varying-ranch",
   "metadata": {},
   "source": [
    "## Obtención del año\n",
    "### Aplicamos un patrón de búsqueda\n",
    "Creamos un diccionario cuyos valores son todos los años en la expresión \"Año xxxx\" y cuyas claves son el identificador del token que lo contiene. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "persistent-jimmy",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Inicializa el matcher con el vocabulario compartido\n",
    "matcher = Matcher(nlp.vocab)\n",
    "\n",
    "# Crea un patrón que encuentre \"Año xxxx\".\n",
    "pattern = [{\"LOWER\": \"año\"}, {\"IS_DIGIT\": True}]\n",
    "\n",
    "# Añade el patrón al matcher y usa el matcher sobre el documento\n",
    "matcher.add(\"AÑO\", [pattern])\n",
    "matches = matcher(doc)\n",
    "\n",
    "# Inicializamos el diccionario\n",
    "años = {}\n",
    "\n",
    "# Itera sobre los resultados para rellenar el diccionario `años`\n",
    "for match_id, start, end in matches:\n",
    "    años[start+1] = int(doc[start+1].text)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "aboriginal-peter",
   "metadata": {},
   "source": [
    "Si deseas ver cómo es este diccionario, descomenta y ejecuta el siguiente código"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "supported-equation",
   "metadata": {},
   "outputs": [],
   "source": [
    "# años"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "choice-approach",
   "metadata": {},
   "source": [
    "### Asignamos a cada persona un año\n",
    "Vamos a crear para ello una extensión para cada entidad denominada `tiempo`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "christian-holiday",
   "metadata": {},
   "outputs": [],
   "source": [
    "Span.set_extension(\"tiempo\", default=False, force=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "retained-diameter",
   "metadata": {},
   "source": [
    "Ahora calculamos la etiqueta en cada entidad nombrada. Esto es una tarea tediosa porque hay que aplicar computacionalmente la regla: a cada entidad le corresponde el año indicado en el primer *token* por encima de ella misma y que se encuentra en el diccionario `años`. Veámoslo con un ejemplo del extracto de prueba:\n",
    "- La persona \"Bartolomé Fernández\" comienza en el token 147 y termina en el 149. Constátelo ejecutanto `doc[147:149]`.\n",
    "- El diccionario de `años` muestra que al token 7 le corresponde el año 1698. Al token 160 el 1773. Constátelo ejecutanto `años[7]` y `años[160]`.\n",
    "- Está claro que a esta persona le corresponde el año 1698, del token 7. Programaremos el año que está justo encima."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "respiratory-pathology",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Creamos una lista con las claves del diccionario `años`. Y variables auxiliares.\n",
    "años_claves = list(años.keys())\n",
    "años_claves.sort()\n",
    "años_len = len(años_claves)\n",
    "aux0 = 0\n",
    "aux1 = 1\n",
    "\n",
    "# Ahora recorremos las entidades del documento y asignamos el año en cada entidad nombrada\n",
    "for ent in doc.ents:\n",
    "    if ent.label_ == \"PER\":\n",
    "        # Calculamos el id del token que comienza la entidad:\n",
    "        comienzo = ent.start\n",
    "        \n",
    "        if comienzo < años_claves[0]:\n",
    "            continue\n",
    "        else:\n",
    "            if años_claves[aux0] < comienzo < años_claves[aux1]:\n",
    "                ent._.tiempo = años.get(años_claves[aux0])\n",
    "            elif comienzo > años_claves[aux0] and comienzo > años_claves[aux1]:\n",
    "                aux0 = aux1\n",
    "                if aux1 + 1 < años_len:\n",
    "                    aux1 += 1\n",
    "                    ent._.tiempo = años.get(años_claves[aux0])\n",
    "                else:\n",
    "                    años_claves.append(comienzo + 1000)\n",
    "                    aux1 += 1\n",
    "                    ent._.tiempo = años.get(años_claves[aux0])\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "surprising-wedding",
   "metadata": {},
   "source": [
    "### Veamos algunos ejemplos de lo que hemos conseguido"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "armed-service",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Simon Queipo --- Año: 1698\n",
      "Bartolome Fernandez --- Año: 1698\n",
      "Don Joseph Antonio de Herías --- Año: 1773\n",
      "Juan García de Zibran --- Año: 1773\n"
     ]
    }
   ],
   "source": [
    "inicio = 130\n",
    "final = 190\n",
    "\n",
    "for ent in doc.ents:\n",
    "    if ent.label_ == 'PER' and (inicio <= ent.start <= final):\n",
    "         print(ent.text, '--- Año:', ent._.tiempo)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "placed-framework",
   "metadata": {},
   "source": [
    "## Obtención de la parroquia\n",
    "En el *notebook* `Z_Ayudas.ipynb` tenemos una lista con todas las entradas de parroquias del censo. Creamos un patrón de Phrase Matcher que reconozca cada una y la etiquete convenientemente. Vamos a usar la función `verificar_matcher` para grabar las etiquetas. Por ejemplo, en la frase \"PARROQUIA DE ARANIEGO(PARAJAS)\", se le asignará la etiqueta `Parajas`. \n",
    "\n",
    "IMPORTANTE: Todas las entradas de parroquias del documento txt deben estar en mayúsculas y en líneas aisladas."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "weird-negative",
   "metadata": {},
   "source": [
    "### Aplicamos un patrón de búsqueda usando variables de apoyo\n",
    "El *notebook* Z_Ayudas.ipynb contiene listas de las variantes ortográficas de los pueblos que aparecen en censo. También, identificaciones con el nombre actual y otras variables de ayuda para el proceso automático que nos traemos entre manos. Por ejemplo"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "literary-genre",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Nota: esta función requiere los siguientes módulo o funciones:\n",
      " from spacy.matcher import Matcher, PhraseMatcher\n",
      " from spacy.tokens import Span\n",
      " Si no los usa se producirá un error.\n",
      "Se han encontrado 2 concordancias con el patrón.\n"
     ]
    }
   ],
   "source": [
    "nombre_extensión = 'parroquia'\n",
    "parroquias = verifica_matcher(nlp, doc, nombre_extensión, PhraseM=list(ayuda_parroquias.keys()), ayuda=ayuda_parroquias)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "statistical-browser",
   "metadata": {},
   "source": [
    "Si deseas ver cómo es este diccionario, descomenta y ejecuta el siguiente código"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "latin-brazilian",
   "metadata": {},
   "outputs": [],
   "source": [
    "# parroquias"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "narrow-lambda",
   "metadata": {},
   "source": [
    "### Asignamos a cada persona una parroquia\n",
    "Vamos a crear para ello una extensión para cada entidad denominada `parroquia_asignada`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "worth-netscape",
   "metadata": {},
   "outputs": [],
   "source": [
    "Span.set_extension(\"parroquia_asignada\", default=False, force=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "intensive-duplicate",
   "metadata": {},
   "source": [
    "Ahora calculamos la etiqueta en cada entidad nombrada. Se realizará de forma análoga a como hizimos con la asignación de un año a cada persona."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "variable-navigation",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Creamos una lista con las claves del diccionario `parroquias`. Y variables auxiliares.\n",
    "parroquias_claves = list(parroquias.keys())\n",
    "parroquias_claves.sort()\n",
    "parroquias_len = len(parroquias_claves)\n",
    "aux0 = 0\n",
    "aux1 = 1\n",
    "\n",
    "# Ahora recorremos las entidades del documento y asignamos el año en cada entidad nombrada\n",
    "for ent in doc.ents:\n",
    "    if ent.label_ == \"PER\":\n",
    "        # Calculamos el id del token que comienza la entidad:\n",
    "        comienzo = ent.start\n",
    "        \n",
    "        if comienzo < parroquias_claves[0]:\n",
    "            continue\n",
    "        else:\n",
    "            if parroquias_claves[aux0] < comienzo < parroquias_claves[aux1]:\n",
    "                ent._.parroquia_asignada = parroquias.get(parroquias_claves[aux0]).get('etiqueta')\n",
    "            elif comienzo > parroquias_claves[aux0] and comienzo > parroquias_claves[aux1]:\n",
    "                aux0 = aux1\n",
    "                if aux1 + 1 < parroquias_len:\n",
    "                    aux1 += 1\n",
    "                    ent._.parroquia_asignada = parroquias.get(parroquias_claves[aux0]).get('etiqueta')\n",
    "                else:\n",
    "                    parroquias_claves.append(comienzo + 10000)\n",
    "                    aux1 += 1\n",
    "                    ent._.parroquia_asignada = parroquias.get(parroquias_claves[aux0]).get('etiqueta')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ruled-technician",
   "metadata": {},
   "source": [
    "### Veamos algunos ejemplos de lo que hemos conseguido"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "recent-brown",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Don Joseph Antonio de Herías 175 ----- parroquia: Herías\n",
      "Juan García de Zibran 186 ----- parroquia: Herías\n",
      "don Juan López Castrillón 197 ----- parroquia: Herías\n",
      "Hijodalgo Notorio 202 ----- parroquia: Herías\n",
      "Ambrosio de la Rua 212 ----- parroquia: Herías\n",
      "Juan 219 ----- parroquia: Herías\n",
      "Nicolás 224 ----- parroquia: Herías\n",
      "Pedro 226 ----- parroquia: Herías\n",
      "Ambrosio 230 ----- parroquia: Herías\n",
      "Hijosdalgo Notorios 232 ----- parroquia: Herías\n",
      "Pedro Fernández de Mera 240 ----- parroquia: Herías\n",
      "Lorenzo 247 ----- parroquia: Herías\n",
      "Juan Fernández Herías 257 ----- parroquia: Herías\n",
      "Santiago Fernández Loredo 269 ----- parroquia: Herías\n",
      "Pedro 275 ----- parroquia: Herías\n"
     ]
    }
   ],
   "source": [
    "for ent in doc.ents[20:40]:\n",
    "    if ent._.parroquia_asignada != None and ent.label_ == 'PER':\n",
    "        print(ent.text, ent.start , '-----', 'parroquia: ' + str(ent._.parroquia_asignada))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "continental-delicious",
   "metadata": {},
   "source": [
    "## Obteniendo localidades\n",
    "En el *notebook* `Z_Ayudas.ipynb` tenemos una lista con todas las entradas de localidades del censo. Algunas de ellas pueden hacer referencia a más de una localidad. En los casos de ambigüedad `verifica_matcher` pregunta al usuario qué escribir. Para la mayoría de casos, la función sugiere la respuesta correcta, ¡pero hay que estar atentos si se estudia el censo al completo y no sólo el ejemplo que está colgado en este repositorio de Github! Véase los siguientes ejemplos:\n",
    "\n",
    "- \"CARCEDO\" o \"CARZEDO\" en el censo puede hacer referencia a \"Carcedo de Lago\" (los dos primeros), pero es \"Carcedo de Lomes\" para los dos segundos.\n",
    "- En \"CASTANEDO Y VILLAR DE SAN PEDRO\", el PhraseMatcher reconoce bien \"CASTANEDO\", pero \"VILLAR DE SAN PEDRO\" tiene tres posibilidades, a saber \"Villar de sapos\" por reconocer la palabra \"VILLAR\", \"Villar de Castanedo\" por reconocer \"VILLAR DE SAN PEDRO\" y \"San Pedro\" por reconocer \"SAN PEDRO\". La correcta es \"Villar de Castanedo\". Las demás opciones las pasaremos escribiendo la palabra \"parar\".\n",
    "\n",
    "\n",
    "IMPORTANTE: Todas las entradas de localidades del documento txt deben estar en mayúsculas y en líneas aisladas. Además, cuando se escribe una etiqueta a mano, es decir, la respuesta no es ni \"sí\", ni \"parar\", ni \"v\", se tiene que escribir igual que lo detalla el diccionario `ayuda_localidades` del *notebook* `Z_Ayudas.ipynb`.\n",
    "\n",
    "### Aplicamos un patrón de búsqueda y usamos variables de apoyo\n",
    "De forma general, las variables de apoyo sirven para automatizar la asignación de etiquetas."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "close-climate",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Nota: esta función requiere los siguientes módulo o funciones:\n",
      " from spacy.matcher import Matcher, PhraseMatcher\n",
      " from spacy.tokens import Span\n",
      " Si no los usa se producirá un error.\n",
      "Se han encontrado 7 concordancias con el patrón.\n"
     ]
    }
   ],
   "source": [
    "nombre_extensión3 = 'lugar'\n",
    "localidades = verifica_matcher(nlp, doc, nombre_extensión3, PhraseM=list(ayuda_localidades.keys()), ayuda=ayuda_localidades, quitarPM=list(ayuda_parroquias.keys()))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bearing-device",
   "metadata": {},
   "source": [
    "Si quieres ver cómo es este diccionario, descomenta y ejecuta el siguiente código."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "mechanical-statistics",
   "metadata": {},
   "outputs": [],
   "source": [
    "# localidades"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "global-reproduction",
   "metadata": {},
   "source": [
    "Hay entidades de persona que están registrada bajo varias localidades a la vez. Por ejemplo, aquellos bajo la entrada de localidad \"COBA, FURADA Y RUBIEIRO\". Por ello, a cada persona le asignaremos como lugar una lista de localidades. Para ello necesitamos reestructurar el diccionario `localidades` de esta forma:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "cleared-bottle",
   "metadata": {},
   "outputs": [],
   "source": [
    "localidades_new = {}\n",
    "\n",
    "for clave, dic in localidades.items():\n",
    "    if localidades_new.get(dic['id'][0]) == None:\n",
    "        localidades_new[dic['id'][0]] = {\n",
    "            'id': dic['id'],\n",
    "            'etiqueta': [dic['etiqueta']]\n",
    "        } \n",
    "    else: \n",
    "        localidades_new[dic['id'][0]]['etiqueta'].append(dic['etiqueta'])\n",
    "        \n",
    "        "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ancient-cinema",
   "metadata": {},
   "source": [
    "Si quieres ver cómo es este diccionario, descomenta y ejecuta el siguiente código."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "indonesian-journal",
   "metadata": {},
   "outputs": [],
   "source": [
    "# localidades_new"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "pursuant-weapon",
   "metadata": {},
   "source": [
    "### Asignamos a cada persona una localidad\n",
    "Vamos a crear para ello una extensión para cada entidad denominada `lugar_asignado`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "increasing-injection",
   "metadata": {},
   "outputs": [],
   "source": [
    "Span.set_extension(\"lugar_asignado\", default=False, force=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "liquid-operator",
   "metadata": {},
   "source": [
    "Ahora calculamos la etiqueta en cada entidad nombrada. Se realizará de forma análoga a como hizimos con la asignación de un año a cada persona."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "impossible-crawford",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Creamos una lista con las claves del diccionario `parroquias`. Y variables auxiliares.\n",
    "localidades_claves = list(localidades_new.keys())\n",
    "localidades_claves.sort()\n",
    "localidades_len = len(localidades_claves)\n",
    "aux0 = 0\n",
    "aux1 = 1\n",
    "\n",
    "# Ahora recorremos las entidades del documento y asignamos la lista de localidades\n",
    "for ent in doc.ents:\n",
    "    if ent.label_ == \"PER\":\n",
    "        # Calculamos el id del token que comienza la entidad:\n",
    "        comienzo = ent.start        \n",
    "        if comienzo < localidades_claves[0]:\n",
    "            continue\n",
    "        else:\n",
    "            if localidades_claves[aux0] < comienzo < localidades_claves[aux1]:\n",
    "                ent._.lugar_asignado = localidades_new.get(localidades_claves[aux0]).get('etiqueta')\n",
    "            elif comienzo > localidades_claves[aux0] and comienzo > localidades_claves[aux1]:\n",
    "                aux0 = aux1\n",
    "                if aux1 + 1 < localidades_len:\n",
    "                    aux1 += 1\n",
    "                    ent._.lugar_asignado = localidades_new.get(localidades_claves[aux0]).get('etiqueta')\n",
    "                else:\n",
    "                    localidades_claves.append(comienzo + 10000)\n",
    "                    aux1 += 1\n",
    "                    ent._.lugar_asignado = localidades_new.get(localidades_claves[aux0]).get('etiqueta')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "incident-court",
   "metadata": {},
   "source": [
    "## Desasignar lugar a empadronadores locales\n",
    "Las EENN de personas que aparecen en la sección de \"Empadronadores locales\" no deben tener un `lugar_asignado`. Sin embargo, de forma automática, por reglas, les ha sido asignado. Debemos revertir esta acción."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "tough-helmet",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Nota: esta función requiere los siguientes módulo o funciones:\n",
      " from spacy.matcher import Matcher, PhraseMatcher\n",
      " from spacy.tokens import Span\n",
      " Si no los usa se producirá un error.\n",
      "Se han encontrado 2 concordancias con el patrón.\n"
     ]
    }
   ],
   "source": [
    "nombre_extensión4 = 'empadronadores'\n",
    "empadronadores = verifica_matcher(nlp, doc, nombre_extensión4, PhraseM=['Empadronadores locales:', 'Empadronadores Locales:'], ayuda={'EMPADRONADORES LOCALES:': 'Emp'})"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dental-tonight",
   "metadata": {},
   "source": [
    "Si quieres ver cómo es este diccionario, descomenta y ejecuta el siguiente código."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "fitting-diving",
   "metadata": {},
   "outputs": [],
   "source": [
    "# empadronadores"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "stupid-cradle",
   "metadata": {},
   "source": [
    "### El siguiente paso realiza la desasignación en sí"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "democratic-memorial",
   "metadata": {},
   "outputs": [],
   "source": [
    "empadronadores_claves = list(empadronadores.keys())\n",
    "empadronadores_claves.sort()\n",
    "\n",
    "\n",
    "registro = []\n",
    "for i in empadronadores_claves:\n",
    "    for j in localidades_claves:\n",
    "        if j >= i:\n",
    "            registro.append((i, j))\n",
    "            break\n",
    "\n",
    "for ent in doc.ents:\n",
    "    if ent.label_ == 'PER':\n",
    "        comienzo = ent.start\n",
    "        for tupla in registro:\n",
    "            if tupla[0] <= comienzo <= tupla[1]:\n",
    "                ent._.lugar_asignado = False"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "continent-individual",
   "metadata": {},
   "source": [
    "## Tabulando los datos\n",
    "La tabla tendrá las columnas siguientes:\n",
    "- Nombre\n",
    "- Año\n",
    "- Parroquia de\n",
    "- Longitud parr.\n",
    "- Latitud parr.\n",
    "- Localidad 1\n",
    "- Longitud 1\n",
    "- Latitud 1\n",
    "- ...\n",
    "\n",
    "Hay hasta tres casillas para localidad y su geolocalización porque en el censo completo hay entradas que están agrupados con hasta tres localidades distintas. Por ejemplo, véase en el padrón completo las entradas referentes a \"COBA, FURADA Y RUBIEIRO\"."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "honey-biodiversity",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Abrimos el documento para guardar los datos.\n",
    "with open(direcciónpueblos, 'w', encoding='utf8') as f:\n",
    "    \n",
    "    # Escribimos los títulos de tabla\n",
    "    f.write('Nombre' + '\\t' +\n",
    "            'Año' + '\\t' +\n",
    "            'Parroquia de' + '\\t' +\n",
    "            'Latitud parr.' + '\\t' +\n",
    "            'Longitud parr.' + '\\t' +\n",
    "            'Localidad 1' + '\\t' +\n",
    "            'Latitud 1' + '\\t' +\n",
    "            'Longitud 1' + '\\t' +\n",
    "            'Localidad 2' + '\\t' +\n",
    "            'Latitud 2' + '\\t' +\n",
    "            'Longitud 2' + '\\t' + \n",
    "            'Localidad 3' + '\\t' +\n",
    "            'Latitud 3' + '\\t' +\n",
    "            'Longitud 3' +     \n",
    "            '\\n')\n",
    "    \n",
    "    # Recorremos las entidades nombradas.\n",
    "    for ent in doc.ents:\n",
    "        \n",
    "        if ent.label_ == 'PER':\n",
    "            Nombre = ent.text\n",
    "            Año = str(ent._.tiempo)\n",
    "            Parroquia = ent._.parroquia_asignada\n",
    "            if Parroquia != False:\n",
    "                dic = longitud_latitud.get(Parroquia)\n",
    "                Latitud_parr = str(dic.get('Latitud'))\n",
    "                Longitud_parr = str(dic.get('Longitud'))\n",
    "            else:\n",
    "                Parroquia = str(None)\n",
    "                Latitud_parr = str(None)\n",
    "                Longitud_parr = str(None)\n",
    "            \n",
    "            localidades = ent._.lugar_asignado\n",
    "            if localidades == False:\n",
    "                localidades = []\n",
    "                \n",
    "            Localidad1 = str(None)\n",
    "            Localidad2 = str(None)\n",
    "            Localidad3 = str(None)\n",
    "            Latitud1 = str(None)\n",
    "            Latitud2 = str(None)\n",
    "            Latitud3 = str(None)\n",
    "            Longitud1 = str(None)\n",
    "            Longitud2 = str(None)\n",
    "            Longitud3 = str(None)\n",
    "            \n",
    "            if len(localidades) >= 1:\n",
    "                Localidad1 = localidades[0]\n",
    "                info = longitud_latitud.get(Localidad1)\n",
    "                Longitud1 = str(info['Longitud'])\n",
    "                Latitud1 = str(info['Latitud'])\n",
    "                \n",
    "            if len(localidades) >= 2:\n",
    "                Localidad2 = localidades[1]\n",
    "                info = longitud_latitud.get(Localidad2)\n",
    "                Longitud2 = str(info['Longitud'])\n",
    "                Latitud2 = str(info['Latitud'])\n",
    "                \n",
    "            if len(localidades) >= 3:\n",
    "                Localidad3 = localidades[2]\n",
    "                info = longitud_latitud.get(Localidad3)\n",
    "                Longitud3 = str(info['Longitud'])\n",
    "                Latitud3 = str(info['Latitud'])\n",
    "                            \n",
    "            \n",
    "            # Escribimos la línea.\n",
    "            f.write(Nombre + '\\t' +\n",
    "            Año + '\\t' +\n",
    "            Parroquia + '\\t' +\n",
    "            Latitud_parr + '\\t' +\n",
    "            Longitud_parr + '\\t' +\n",
    "            Localidad1 + '\\t' +\n",
    "            Latitud1 + '\\t' +\n",
    "            Longitud1 + '\\t' + \n",
    "            Localidad2 + '\\t' +\n",
    "            Latitud2 + '\\t' +\n",
    "            Longitud2 + '\\t' +\n",
    "            Localidad3 + '\\t' +\n",
    "            Latitud3 + '\\t' +\n",
    "            Longitud3 +        \n",
    "            '\\n')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "polish-desperate",
   "metadata": {},
   "source": [
    "## Serialización\n",
    "Vamos a serializar guardando a parte un diccionario con la información de todas las extensiones definidas en el doc. Al momento de revertir la serialización hay que volver a crearlas."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "found-comment",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Nota: esta función requiere los siguientes módulo o funciones:\n",
      " import spacy\n",
      " from spacy.tokens import DocBin\n",
      " Si no los usa se producirá un error.\n"
     ]
    }
   ],
   "source": [
    "serializacion(doc, direccionbin_tags)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "devoted-volume",
   "metadata": {},
   "source": [
    "## Revertir serialización\n",
    "Ahora, cuando quieras seguir experimentando con los resultados obtenidos, no tienes que ejecutar de nuevo todo el código de cálculo de etiquetas. Basta con que reviertas la serialización con el siguiente código. Nótese que es necesario decirle a SpaCy información de las etiquetas que queremos recuperar."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "representative-blackjack",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Nota: esta función requiere los siguientes módulo o funciones:\n",
      " import spacy\n",
      " from spacy.tokens import Doc\n",
      " from spacy.tokens import DocBin\n",
      " Si no los usa se producirá un error.\n"
     ]
    }
   ],
   "source": [
    "extensiones = {\n",
    "    \"tiempo\": {\n",
    "        'tipo': 'span',\n",
    "        'default': False,\n",
    "        'force': True\n",
    "    },\n",
    "    \"parroquia\": {\n",
    "        'tipo': 'span',\n",
    "        'default': False,\n",
    "        'force': True\n",
    "    },\n",
    "    \"parroquia_asignada\": {\n",
    "        'tipo': 'span',\n",
    "        'default': False,\n",
    "        'force': True\n",
    "    },\n",
    "    \"lugar_asignado\": {\n",
    "        'tipo': 'span',\n",
    "        'default': False,\n",
    "        'force': True\n",
    "    },\n",
    "    \"lugar\": {\n",
    "        'tipo': 'span',\n",
    "        'default': False,\n",
    "        'force': True\n",
    "    },\n",
    "    \"empadronadores\": {\n",
    "        'tipo': 'span',\n",
    "        'default': False,\n",
    "        'force': True\n",
    "    }\n",
    "}\n",
    "\n",
    "doc = revertir_serializacion(direccionbin_tags, nlp, extensiones=extensiones)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "nuclear-series",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
